name: Organize Google Photos Files

on:
  workflow_dispatch:  # Manual trigger only
    inputs:
      dry_run:
        description: 'Dry run mode (no actual changes)'
        required: false
        type: boolean
        default: true
      partial_albums:
        description: 'Create albums even if some files are missing (recommended)'
        required: false
        type: boolean
        default: true
      min_files_threshold:
        description: 'Minimum number of files required to create an album'
        required: false
        type: number
        default: 1

env:
  PYTHONUNBUFFERED: 1

jobs:
  organize:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 2 hours max
    permissions:
      contents: read
      actions: read  # Needed to download artifacts
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install https://github.com/xob0t/google_photos_mobile_client/archive/refs/heads/main.zip --force-reinstall
      
      - name: Download FTP structure manifest
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "ðŸ“¥ Downloading FTP structure manifest from artifacts..."
          
          # Find the most recent successful run of generate-ftp-tree workflow
          LATEST_RUN=$(gh run list --workflow=.github/workflows/generate-ftp-tree.yml --status=completed --limit=1 --json databaseId --jq ".[0].databaseId")
          
          if [ -n "$LATEST_RUN" ] && [ "$LATEST_RUN" != "null" ]; then
            echo "âœ… Found workflow run: $LATEST_RUN"
            
            # Download the ftp-structure-manifest artifact
            if gh run download $LATEST_RUN --name ftp-structure-manifest 2>/dev/null; then
              echo "âœ… Successfully downloaded manifest artifact"
              
              # List downloaded files
              echo "ðŸ“‚ Downloaded files:"
              ls -lh ftp_structure_manifest.json ftp_structure_tree.txt 2>/dev/null || ls -lh
              
              if [ -f "ftp_structure_manifest.json" ]; then
                echo "âœ… Found ftp_structure_manifest.json"
                # Show basic stats
                python3 -c "import json; data = json.load(open('ftp_structure_manifest.json')); stats = data['statistics']; print(f\"Total files: {stats['total_files']}\"); print(f\"Total size: {stats['total_size_gb']} GB\")"
              else
                echo "âŒ ftp_structure_manifest.json not found in artifact"
                exit 1
              fi
            else
              echo "âŒ Failed to download manifest artifact"
              echo "Please run 'Generate FTP Structure Tree' workflow first"
              exit 1
            fi
          else
            echo "âŒ No successful 'Generate FTP Structure Tree' workflow runs found"
            echo "Please run that workflow first to generate the manifest"
            exit 1
          fi
      
      - name: Download upload state (for media keys)
        continue-on-error: true
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "ðŸ“¥ Downloading upload state (contains media keys)..."
          
          # Find the most recent successful run of transfer workflow
          LATEST_RUN=$(gh run list --workflow=.github/workflows/transfer.yml --status=completed --limit=1 --json databaseId --jq ".[0].databaseId")
          
          if [ -n "$LATEST_RUN" ] && [ "$LATEST_RUN" != "null" ]; then
            echo "âœ… Found workflow run: $LATEST_RUN"
            
            # Download and extract the upload-state artifact
            if gh run download $LATEST_RUN --name upload-state --dir . 2>/dev/null; then
              echo "âœ… Successfully downloaded upload-state artifact"
              
              if [ -f "upload_state.json" ]; then
                echo "âœ… Found upload_state.json"
                # Show basic stats
                python3 -c "import json; data = json.load(open('upload_state.json')); completed = data.get('completed', {}); version = data.get('version', 'unknown'); completed_count = len(completed) if isinstance(completed, dict) else len(completed); media_key_count = sum(1 for info in completed.values() if isinstance(info, dict) and info.get('media_key') is not None) if isinstance(completed, dict) else 0; print(f'Version: {version}'); print(f'Completed uploads: {completed_count}'); print(f'With media keys: {media_key_count}')"
              else
                echo "âš ï¸ upload_state.json not found - will not be able to organize files"
              fi
            else
              echo "âš ï¸ Failed to download upload-state artifact"
              echo "Organization will be limited without media keys"
            fi
          else
            echo "âš ï¸ No successful transfer workflow runs found"
            echo "Upload files first using 'FTP to Google Photos Transfer' workflow"
          fi
      
      - name: Build Google Photos cache
        env:
          GP_AUTH_DATA: ${{ secrets.GP_AUTH_DATA }}
        run: |
          echo "ðŸ”„ Building Google Photos cache to enable file detection..."
          echo "This may take several minutes depending on library size"
          
          # Create a script to properly build the cache
          cat > build_cache.py << 'EOF'
          import sys
          import os
          import sqlite3
          from pathlib import Path
          from gpmc import Client
          
          # Get auth data
          auth_data = os.environ.get('GP_AUTH_DATA')
          if not auth_data:
              print("âŒ GP_AUTH_DATA not set")
              sys.exit(1)
          
          cache_path = Path.home() / ".cache" / "gpmc" / "library.db"
          cache_exists = cache_path.exists()
          
          if cache_exists:
              # Check current cache status
              try:
                  conn = sqlite3.connect(cache_path)
                  cursor = conn.cursor()
                  cursor.execute("SELECT COUNT(*) FROM remote_media")
                  count = cursor.fetchone()[0]
                  conn.close()
                  print(f"ðŸ“Š Existing cache contains {count} items")
              except Exception as e:
                  print(f"âš ï¸ Could not read existing cache: {e}")
                  print("   Will rebuild cache from scratch")
                  cache_exists = False
          else:
              print("ðŸ†• No existing cache found - will build from scratch")
          
          # Initialize client - this may initialize the cache automatically
          print("ðŸ“¡ Connecting to Google Photos...")
          client = Client(auth_data=auth_data)
          print("âœ… Client connected")
          
          # Update the cache - this should populate it if empty, or update it if it exists
          # According to gpmc behavior, update_cache() will:
          # - Initialize cache if it doesn't exist
          # - Fetch new items if cache exists but is stale
          # - Use pagination to handle large libraries
          print("ðŸ”„ Updating cache with library metadata...")
          print("   This operation will fetch all media from your Google Photos library")
          print("   It may take several minutes for large libraries...")
          
          try:
              client.update_cache(show_progress=True)
              print("âœ… Cache update completed")
          except Exception as e:
              print(f"âŒ Error updating cache: {e}")
              import traceback
              traceback.print_exc()
              sys.exit(1)
          
          # Verify cache contents
          if cache_path.exists():
              conn = sqlite3.connect(cache_path)
              cursor = conn.cursor()
              cursor.execute("SELECT COUNT(*) FROM remote_media")
              count = cursor.fetchone()[0]
              print(f"ðŸ“Š Cache now contains {count} media items")
              
              if count == 0:
                  print("âš ï¸ WARNING: Cache is empty after update!")
                  print("   This likely means:")
                  print("   1. Your Google Photos library is empty, OR")
                  print("   2. There's an authentication or API issue")
                  print("   Files cannot be organized if cache is empty")
              else:
                  # Show sample filenames to help with debugging
                  cursor.execute("SELECT file_name FROM remote_media LIMIT 10")
                  samples = cursor.fetchall()
                  if samples:
                      print("ðŸ“ Sample filenames in cache:")
                      for (filename,) in samples:
                          print(f"   - {filename}")
              
              conn.close()
          else:
              print("âŒ Cache file not found after update!")
              print(f"   Expected location: {cache_path}")
              sys.exit(1)
          EOF
          
          python3 build_cache.py
          
          # Verify cache was created
          CACHE_PATH="$HOME/.cache/gpmc/library.db"
          if [ -f "$CACHE_PATH" ]; then
            CACHE_SIZE=$(du -h "$CACHE_PATH" | cut -f1)
            echo "âœ… Cache available at $CACHE_PATH (size: $CACHE_SIZE)"
            
            # Show final cache statistics
            python3 -c "import sqlite3, os; conn = sqlite3.connect(os.environ.get('CACHE_PATH')); cursor = conn.cursor(); cursor.execute('SELECT COUNT(*) FROM remote_media'); count = cursor.fetchone()[0]; print(f'ðŸ“Š Final cache size: {count} items'); conn.close()" || echo "âš ï¸ Could not read cache statistics"
          else
            echo "âŒ Cache file not found at expected location: $CACHE_PATH"
            echo "   This will cause file organization to fail"
            exit 1
          fi
      
      - name: Run organization script
        env:
          GP_AUTH_DATA: ${{ secrets.GP_AUTH_DATA }}
        run: |
          # Build command line arguments
          ARGS=""
          
          # Determine if dry run mode
          if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
            echo "ðŸ” Running in DRY RUN mode - no changes will be made"
            ARGS="$ARGS --dry-run"
          else
            echo "ðŸš€ Running in LIVE mode - files will be organized"
          fi
          
          # Determine if partial albums are disabled
          if [ "${{ github.event.inputs.partial_albums }}" = "false" ]; then
            echo "âš ï¸ Partial albums disabled - only complete albums will be created"
            ARGS="$ARGS --no-partial-albums"
          else
            echo "âœ… Partial albums enabled - will create albums even if some files are missing"
          fi
          
          # Add min files threshold
          MIN_FILES="${{ github.event.inputs.min_files_threshold }}"
          if [ -n "$MIN_FILES" ] && [ "$MIN_FILES" != "1" ]; then
            echo "âš™ï¸ Minimum files threshold: $MIN_FILES"
            ARGS="$ARGS --min-files=$MIN_FILES"
          fi
          
          # Run the script
          python3 organize_gphotos.py $ARGS
        continue-on-error: false
      
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: organization-logs
          path: organize_gphotos.log
          retention-days: 30
      
      - name: Create summary
        if: always()
        run: |
          echo "# Google Photos Organization Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
            echo "ðŸ” **Mode:** Dry Run (no changes made)" >> $GITHUB_STEP_SUMMARY
          else
            echo "ðŸš€ **Mode:** Live (files organized)" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Partial albums:** ${{ github.event.inputs.partial_albums }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Min files threshold:** ${{ github.event.inputs.min_files_threshold }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "organize_gphotos.log" ]; then
            # Extract statistics from log file
            SUCCESSFUL=$(grep -c "âœ… Successfully added" organize_gphotos.log || echo "0")
            FAILED=$(grep -c "âŒ Failed to add" organize_gphotos.log || echo "0")
            SKIPPED=$(grep -c "âš ï¸ Not found in any cache" organize_gphotos.log || echo "0")
            PARTIAL=$(grep -c "âš ï¸ Partial album:" organize_gphotos.log || echo "0")
            
            echo "## Results" >> $GITHUB_STEP_SUMMARY
            echo "- âœ… Successful: $SUCCESSFUL albums" >> $GITHUB_STEP_SUMMARY
            echo "- âŒ Failed: $FAILED albums" >> $GITHUB_STEP_SUMMARY
            echo "- â­ï¸ Skipped: $SKIPPED files" >> $GITHUB_STEP_SUMMARY
            if [ "$PARTIAL" -gt "0" ]; then
              echo "- âš ï¸ Partial albums: $PARTIAL (some files missing)" >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Check for missing files report
            if grep -q "MISSING FILES REPORT" organize_gphotos.log; then
              echo "## Missing Files Detected" >> $GITHUB_STEP_SUMMARY
              echo "âš ï¸ Some files could not be found in cache. See detailed log for:" >> $GITHUB_STEP_SUMMARY
              echo "- Which albums have missing files" >> $GITHUB_STEP_SUMMARY
              echo "- Specific filenames that are missing" >> $GITHUB_STEP_SUMMARY
              echo "- Recommended actions to resolve the issues" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### Quick Actions" >> $GITHUB_STEP_SUMMARY
              echo "1. Run \`gpmc update-cache\` to refresh the Google Photos cache" >> $GITHUB_STEP_SUMMARY
              echo "2. Verify files were successfully uploaded (check upload_state.json)" >> $GITHUB_STEP_SUMMARY
              echo "3. Re-run this workflow to pick up newly found files" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
            
            if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
              echo "â„¹ï¸ Run again without dry-run mode to actually organize files" >> $GITHUB_STEP_SUMMARY
            else
              echo "âœ… Files have been organized into albums in Google Photos" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "âŒ **Status:** Failed - Check logs for details" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“¥ Download logs from the **Artifacts** section above for details" >> $GITHUB_STEP_SUMMARY
