name: FTP to Google Photos Transfer

on:
  workflow_dispatch:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  push:
    branches:
      - main

env:
  PYTHONUNBUFFERED: 1

jobs:
  transfer:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours max
    
    steps:
      - name: Maximize build disk space
        uses: easimon/maximize-build-space@master
        with:
          root-reserve-mb: 1536        # Reduce to 1.5GB for system (frees ~500MB)
          swap-size-mb: 512            # Reduce swap to 512MB (frees ~500MB)
          remove-dotnet: 'true'        # Remove .NET (~10GB)
          remove-android: 'true'       # Remove Android SDK (~8GB)
          remove-haskell: 'true'       # Remove Haskell (~5GB)
          remove-codeql: 'true'        # Remove CodeQL (~2GB)
          remove-docker-images: 'true' # Remove Docker images (~5GB)
          temp-reserve-mb: 50          # Reduce temp reserve to 50MB (frees ~50MB)
          build-mount-path: '/workspace'
      
      - name: Additional aggressive cleanup
        run: |
          # Remove large unused packages and caches
          sudo apt-get clean
          sudo rm -rf /var/lib/apt/lists/*
          
          # Remove pip cache
          rm -rf ~/.cache/pip
          
          # Remove Python bytecode caches
          find /usr -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null || true
          
          # Remove old logs
          sudo journalctl --vacuum-time=1d
          
          # Remove snap packages if any (can free several GB)
          if command -v snap &> /dev/null; then
            sudo snap list | grep -v "^Name" | awk '{print $1}' | xargs -r sudo snap remove 2>/dev/null || true
            sudo rm -rf /var/lib/snapd
          fi
          
          # Remove large unused tools
          sudo rm -rf /usr/local/lib/android 2>/dev/null || true
          sudo rm -rf /opt/hostedtoolcache/CodeQL 2>/dev/null || true
          
          # Show freed space
          df -h /
      
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          path: 'repo'
      
      - name: Download previous state (if exists)
        continue-on-error: true
        id: download-state
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd repo
          echo "üîç Looking for previous upload state..."
          
          STATE_FOUND=false
          
          # Priority 1: Try to download artifact from previous workflow runs (smart selection)
          # Check up to 10 recent runs to find the most complete state
          CURRENT_RUN_ID=${{ github.run_id }}
          RECENT_RUNS=$(gh run list --workflow=.github/workflows/transfer.yml --status=completed --limit=10 --json databaseId --jq "map(select(.databaseId != $CURRENT_RUN_ID)) | .[].databaseId")
          
          if [ -z "$RECENT_RUNS" ]; then
            echo "‚ö†Ô∏è No previous workflow runs found"
          else
            echo "üìã Found $(echo "$RECENT_RUNS" | wc -l) recent workflow run(s)"
            
            # Try to download and evaluate each artifact to find the most complete one
            BEST_RUN_ID=""
            BEST_FILE_COUNT=0
            TEMP_DIR=$(mktemp -d)
            
            for RUN_ID in $RECENT_RUNS; do
              echo "üîç Checking run $RUN_ID for upload-state artifact..."
              
              # Create a subdirectory for this run's artifact
              RUN_DIR="$TEMP_DIR/run_$RUN_ID"
              mkdir -p "$RUN_DIR"
              
              # Try to download the artifact using --dir to extract directly
              if gh run download "$RUN_ID" --name upload-state --dir "$RUN_DIR" 2>/dev/null; then
                echo "  ‚úÖ Downloaded artifact from run $RUN_ID"
                
                # Artifacts are ZIP files - need to extract them explicitly
                ZIP_FILE=$(find "$RUN_DIR" -name "*.zip" -type f -print -quit 2>/dev/null)
                
                if [ -n "$ZIP_FILE" ]; then
                  echo "  üì¶ Found artifact ZIP, extracting..."
                  if unzip -q "$ZIP_FILE" -d "$RUN_DIR" 2>/dev/null; then
                    echo "  ‚úÖ ZIP extracted successfully"
                  else
                    echo "  ‚ö†Ô∏è Failed to extract ZIP file"
                    continue
                  fi
                fi
                
                # Check if upload_state.json exists in the extracted directory
                if [ -f "$RUN_DIR/upload_state.json" ]; then
                  # Count completed files in this state with validation
                  # Capture jq errors for debugging
                  JQ_ERROR=$(mktemp)
                  FILE_COUNT=$(jq -r '.completed | length' "$RUN_DIR/upload_state.json" 2>"$JQ_ERROR")
                  JQ_EXIT_CODE=$?
                  
                  # Check for jq parsing errors
                  if [ $JQ_EXIT_CODE -ne 0 ]; then
                    echo "  ‚ö†Ô∏è jq parsing error: $(cat "$JQ_ERROR" | head -n 1)"
                    FILE_COUNT=""
                  fi
                  rm -f "$JQ_ERROR"
                  
                  # Validate that FILE_COUNT is a valid non-empty number
                  if [ -z "$FILE_COUNT" ] || ! [[ "$FILE_COUNT" =~ ^[0-9]+$ ]]; then
                    echo "  ‚ö†Ô∏è Invalid or malformed state file (count: '$FILE_COUNT'), treating as 0"
                    FILE_COUNT=0
                  fi
                  
                  echo "  üìä Run $RUN_ID has $FILE_COUNT completed files"
                  
                  # Keep track of the best (most complete) artifact
                  if [ "$FILE_COUNT" -gt "$BEST_FILE_COUNT" ]; then
                    BEST_FILE_COUNT="$FILE_COUNT"
                    BEST_RUN_ID="$RUN_ID"
                    echo "  üèÜ New best: Run $RUN_ID with $FILE_COUNT files"
                  fi
                else
                  echo "  ‚ö†Ô∏è upload_state.json not found in artifact"
                fi
              else
                echo "  ‚ö†Ô∏è No upload-state artifact in run $RUN_ID"
              fi
            done
            
            # Use the best artifact found
            if [ -n "$BEST_RUN_ID" ]; then
              echo ""
              echo "‚úÖ Selected run $BEST_RUN_ID with $BEST_FILE_COUNT completed files"
              cp "$TEMP_DIR/run_$BEST_RUN_ID/upload_state.json" ./upload_state.json
              echo "üìÑ State file size: $(wc -c < upload_state.json) bytes"
              echo "üìÑ Completed files: $BEST_FILE_COUNT"
              STATE_FOUND=true
            else
              echo ""
              echo "‚ö†Ô∏è No valid upload-state artifacts found in any recent run"
            fi
            
            # Cleanup temp directory
            rm -rf "$TEMP_DIR"
          fi
          
          # Priority 2: Fallback to state file in repo (if committed)
          if [ "$STATE_FOUND" = "false" ] && [ -f "upload_state.json" ]; then
            echo "‚úÖ Found state file in repository (fallback)"
            echo "üìÑ Repo state file size: $(wc -c < upload_state.json) bytes"
            STATE_FOUND=true
          fi
          
          if [ "$STATE_FOUND" = "false" ]; then
            echo "‚ÑπÔ∏è No previous state found - will create new state on first run"
          fi
      
      - name: Check state file
        run: |
          if [ -f "repo/upload_state.json" ]; then
            echo "‚úÖ State file found"
            echo "State file size: $(wc -c < repo/upload_state.json) bytes"
            echo "Completed files: $(jq '.completed | length' repo/upload_state.json 2>/dev/null || echo 0)"
          else
            echo "‚ö†Ô∏è State file NOT found - will create new state"
          fi
        working-directory: .
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install rclone
        run: |
          curl https://rclone.org/install.sh | sudo bash
          rclone version
      
      - name: Setup GitHub CLI (for state uploads)
        run: |
          type -p curl >/dev/null || (sudo apt-get update && sudo apt-get install curl -y)
          curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg \
          && sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg \
          && echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null \
          && sudo apt-get update \
          && sudo apt-get install gh -y
        continue-on-error: true
      
      - name: Configure rclone
        run: |
          mkdir -p ~/.config/rclone
          echo "${{ secrets.RCLONE_CONFIG }}" > ~/.config/rclone/rclone.conf
          chmod 600 ~/.config/rclone/rclone.conf
          echo "Rclone config created"
      
      - name: Test rclone connection
        run: |
          rclone lsd Challenger: || echo "Warning: Could not list directories"
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg p7zip-full unzip
      
      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install https://github.com/xob0t/google_photos_mobile_client/archive/refs/heads/main.zip --force-reinstall
          pip install requests
      
      - name: Run transfer script (with periodic state upload)
        env:
          GP_AUTH_DATA: ${{ secrets.GP_AUTH_DATA }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        working-directory: repo
        run: |
          # Run script in background and periodically upload state
          python3 ftp_to_gphotos.py &
          SCRIPT_PID=$!
          
          # Upload state every 30 minutes while script runs
          while kill -0 $SCRIPT_PID 2>/dev/null; do
            sleep 1800  # 30 minutes
            if [ -f "upload_state.json" ]; then
              echo "üì§ Uploading state file (periodic backup)..."
              gh run upload ${{ github.run_id }} upload_state.json --name upload-state --pattern upload_state.json || true
            fi
          done
          
          # Wait for script to finish
          wait $SCRIPT_PID
          SCRIPT_EXIT=$?
          
          # Final state upload
          if [ -f "upload_state.json" ]; then
            echo "üì§ Final state file upload..."
            gh run upload ${{ github.run_id }} upload_state.json --name upload-state --pattern upload_state.json || true
          fi
          
          exit $SCRIPT_EXIT
        continue-on-error: true
      
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: transfer-logs
          path: |
            repo/ftp_to_gphotos.log
          retention-days: 7
      
      - name: Upload state for next run (final)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: upload-state
          path: repo/upload_state.json
          retention-days: 90
          overwrite: true
      
      - name: Check disk space
        if: always()
        run: |
          df -h
          du -sh ~/* 2>/dev/null || true

