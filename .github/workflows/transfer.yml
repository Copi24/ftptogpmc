name: FTP to Google Photos Transfer

on:
  workflow_dispatch:
    inputs:
      ftp_server:
        description: 'Select FTP Server'
        required: true
        default: 'Challenger'
        type: choice
        options:
          - Challenger
          - Sputnik
          - Tamarind
  push:
    branches:
      - master

env:
  PYTHONUNBUFFERED: 1

jobs:
  transfer:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours max
    
    steps:
      - name: Maximize build disk space
        uses: easimon/maximize-build-space@master
        with:
          root-reserve-mb: 1536        # Reduce to 1.5GB for system (frees ~500MB)
          swap-size-mb: 512            # Reduce swap to 512MB (frees ~500MB)
          remove-dotnet: 'true'        # Remove .NET (~10GB)
          remove-android: 'true'       # Remove Android SDK (~8GB)
          remove-haskell: 'true'       # Remove Haskell (~5GB)
          remove-codeql: 'true'        # Remove CodeQL (~2GB)
          remove-docker-images: 'true' # Remove Docker images (~5GB)
          temp-reserve-mb: 50          # Reduce temp reserve to 50MB (frees ~50MB)
          build-mount-path: '/workspace'
      
      - name: Additional aggressive cleanup
        run: |
          # Remove large unused packages and caches
          sudo apt-get clean
          sudo rm -rf /var/lib/apt/lists/*
          
          # Remove pip cache
          rm -rf ~/.cache/pip
          
          # Remove Python bytecode caches
          find /usr -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null || true
          
          # Remove old logs
          sudo journalctl --vacuum-time=1d
          
          # Remove snap packages if any (can free several GB)
          if command -v snap &> /dev/null; then
            sudo snap list | grep -v "^Name" | awk '{print $1}' | xargs -r sudo snap remove 2>/dev/null || true
            sudo rm -rf /var/lib/snapd
          fi
          
          # Remove large unused tools
          sudo rm -rf /usr/local/lib/android 2>/dev/null || true
          sudo rm -rf /opt/hostedtoolcache/CodeQL 2>/dev/null || true
          
          # Show freed space
          df -h /
      
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          path: 'repo'
      
      - name: Download previous state (if exists)
        continue-on-error: true
        id: download-state
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd repo
          echo "üîç Looking for previous upload state..."
          
          STATE_FOUND=false
          
          # Priority 1: Try to download artifact from recent workflow runs
          # Scan last 5 runs to find the most complete state file
          CURRENT_RUN_ID=${{ github.run_id }}
          # Get last 5 successful runs
          RECENT_RUNS=$(gh run list --workflow=.github/workflows/transfer.yml --status=completed --limit=5 --json databaseId --jq "map(select(.databaseId != $CURRENT_RUN_ID)) | .[].databaseId")
          
          BEST_STATE_FILE=""
          MAX_COMPLETED_FILES=-1
          TEMP_BASE=$(mktemp -d)
          
          if [ -n "$RECENT_RUNS" ]; then
            echo "üîç Scanning recent runs for best state file..."
            
            for RUN_ID in $RECENT_RUNS; do
              echo "  ‚Ä¢ Checking run: $RUN_ID"
              RUN_TEMP="$TEMP_BASE/$RUN_ID"
              mkdir -p "$RUN_TEMP"
              
              if gh run download $RUN_ID --name upload-state --dir "$RUN_TEMP" 2>/dev/null; then
                # Extract if zip
                ZIP_FILE=$(find "$RUN_TEMP" -name "*.zip" -type f -print -quit 2>/dev/null)
                if [ -n "$ZIP_FILE" ]; then
                  unzip -q "$ZIP_FILE" -d "$RUN_TEMP" 2>/dev/null || true
                fi
                
                # Find JSON
                JSON_FILE=$(find "$RUN_TEMP" -name "upload_state.json" -type f -print -quit 2>/dev/null)
                
                if [ -n "$JSON_FILE" ]; then
                  # Check completion count
                  COUNT=$(jq -r '.completed | length' "$JSON_FILE" 2>/dev/null || echo "-1")
                  
                  if [ "$COUNT" -gt "$MAX_COMPLETED_FILES" ]; then
                    echo "    ‚úÖ Found better state: $COUNT completed files"
                    MAX_COMPLETED_FILES=$COUNT
                    BEST_STATE_FILE="$JSON_FILE"
                  else
                    echo "    ‚ÑπÔ∏è  State has fewer/equal files ($COUNT vs $MAX_COMPLETED_FILES)"
                  fi
                fi
              else
                echo "    ‚ö†Ô∏è  No state artifact found"
              fi
            done
            
            if [ -n "$BEST_STATE_FILE" ] && [ -f "$BEST_STATE_FILE" ]; then
              echo "üèÜ Selected best state file with $MAX_COMPLETED_FILES completed files"
              cp "$BEST_STATE_FILE" ./upload_state.json
              STATE_FOUND=true
            else
              echo "‚ö†Ô∏è  No valid state files found in recent runs"
            fi
            
            # Cleanup
            rm -rf "$TEMP_BASE"
          else
            echo "‚ö†Ô∏è No previous workflow runs found"
          fi
          
          # Priority 2: Fallback to state file in repo (if committed)
          if [ "$STATE_FOUND" = "false" ] && [ -f "upload_state.json" ]; then
            echo "‚úÖ Found state file in repository (fallback)"
            echo "üìÑ Repo state file size: $(wc -c < upload_state.json) bytes"
            STATE_FOUND=true
          fi
          
          if [ "$STATE_FOUND" = "false" ]; then
            echo "‚ÑπÔ∏è No previous state found - will create new state on first run"
          fi
      
      - name: Check state file
        run: |
          if [ -f "repo/upload_state.json" ]; then
            echo "‚úÖ State file found"
            echo "State file size: $(wc -c < repo/upload_state.json) bytes"
            echo "Completed files: $(jq '.completed | length' repo/upload_state.json 2>/dev/null || echo 0)"
          else
            echo "‚ö†Ô∏è State file NOT found - will create new state"
          fi
        working-directory: .
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install rclone
        run: |
          curl https://rclone.org/install.sh | sudo bash
          rclone version
      
      - name: Setup GitHub CLI (for state uploads)
        run: |
          type -p curl >/dev/null || (sudo apt-get update && sudo apt-get install curl -y)
          curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg \
          && sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg \
          && echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null \
          && sudo apt-get update \
          && sudo apt-get install gh -y
        continue-on-error: true
      
      - name: Configure rclone
        run: |
          mkdir -p ~/.config/rclone
          echo "${{ secrets.RCLONE_CONFIG }}" > ~/.config/rclone/rclone.conf
          chmod 600 ~/.config/rclone/rclone.conf
          echo "Rclone config created"
      
      - name: Test rclone connection
        run: |
          rclone lsd Challenger: || echo "Warning: Could not list directories"
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg p7zip-full unzip
      
      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install https://github.com/xob0t/google_photos_mobile_client/archive/refs/heads/main.zip --force-reinstall
          pip install requests
      
      - name: Run transfer script
        env:
          GP_AUTH_DATA: ${{ secrets.GP_AUTH_DATA }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SELECTED_FTP_SERVER: ${{ github.event.inputs.ftp_server || 'Challenger' }}
        working-directory: repo
        run: |
          # Run the transfer script
          # State is saved after each file and will be uploaded at the end via actions/upload-artifact
          python3 ftp_to_gphotos.py
        continue-on-error: true
      
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: transfer-logs
          path: |
            repo/ftp_to_gphotos.log
          retention-days: 7
      
      - name: Upload state for next run (final)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: upload-state
          path: repo/upload_state.json
          retention-days: 90
          overwrite: true
      
      - name: Check disk space
        if: always()
        run: |
          df -h
          du -sh ~/* 2>/dev/null || true

