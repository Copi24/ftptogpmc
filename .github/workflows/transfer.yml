name: FTP to Google Photos Transfer

on:
  workflow_dispatch:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  push:
    branches:
      - main

env:
  PYTHONUNBUFFERED: 1

jobs:
  transfer:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours max
    
    steps:
      - name: Maximize build disk space
        uses: easimon/maximize-build-space@master
        with:
          root-reserve-mb: 1536        # Reduce to 1.5GB for system (frees ~500MB)
          swap-size-mb: 512            # Reduce swap to 512MB (frees ~500MB)
          remove-dotnet: 'true'        # Remove .NET (~10GB)
          remove-android: 'true'       # Remove Android SDK (~8GB)
          remove-haskell: 'true'       # Remove Haskell (~5GB)
          remove-codeql: 'true'        # Remove CodeQL (~2GB)
          remove-docker-images: 'true' # Remove Docker images (~5GB)
          temp-reserve-mb: 50          # Reduce temp reserve to 50MB (frees ~50MB)
          build-mount-path: '/workspace'
      
      - name: Additional aggressive cleanup
        run: |
          # Remove large unused packages and caches
          sudo apt-get clean
          sudo rm -rf /var/lib/apt/lists/*
          
          # Remove pip cache
          rm -rf ~/.cache/pip
          
          # Remove Python bytecode caches
          find /usr -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null || true
          
          # Remove old logs
          sudo journalctl --vacuum-time=1d
          
          # Remove snap packages if any (can free several GB)
          if command -v snap &> /dev/null; then
            sudo snap list | grep -v "^Name" | awk '{print $1}' | xargs -r sudo snap remove 2>/dev/null || true
            sudo rm -rf /var/lib/snapd
          fi
          
          # Remove large unused tools
          sudo rm -rf /usr/local/lib/android 2>/dev/null || true
          sudo rm -rf /opt/hostedtoolcache/CodeQL 2>/dev/null || true
          
          # Show freed space
          df -h /
      
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          path: 'repo'
      
      - name: Download previous state (if exists)
        continue-on-error: true
        id: download-state
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd repo
          echo "ðŸ” Looking for previous upload state..."
          
          STATE_FOUND=false
          
          # Priority 1: Try to download artifact from previous workflow run (most recent state)
          CURRENT_RUN_ID=${{ github.run_id }}
          LATEST_RUN=$(gh run list --workflow=.github/workflows/transfer.yml --status=completed --limit=5 --json databaseId --jq "map(select(.databaseId != $CURRENT_RUN_ID)) | .[0].databaseId")
          
          if [ -n "$LATEST_RUN" ] && [ "$LATEST_RUN" != "null" ]; then
            echo "ðŸ“¥ Found workflow run: $LATEST_RUN"
            echo "ðŸ” Attempting to download upload-state artifact..."
            
            # Try to download the upload-state artifact from that run
            if gh run download $LATEST_RUN --name upload-state 2>/dev/null; then
              echo "âœ… Successfully downloaded upload-state artifact"
              # The artifact might be in the current directory or a subdirectory
              if [ -f "upload_state.json" ]; then
                echo "ðŸ“„ Artifact state file size: $(wc -c < upload_state.json) bytes"
                STATE_FOUND=true
              else
                # Try to find it in subdirectories
                FOUND_FILE=$(find . -name "upload_state.json" -type f -print -quit 2>/dev/null)
                if [ -n "$FOUND_FILE" ]; then
                  mv "$FOUND_FILE" ./upload_state.json
                  echo "ðŸ“„ Found artifact state file: $(wc -c < upload_state.json) bytes"
                  STATE_FOUND=true
                else
                  echo "âš ï¸ upload_state.json not found in artifact"
                fi
              fi
            else
              echo "âš ï¸ No upload-state artifact found in previous run"
            fi
          else
            echo "âš ï¸ No previous workflow runs found"
          fi
          
          # Priority 2: Fallback to state file in repo (if committed)
          if [ "$STATE_FOUND" = "false" ] && [ -f "upload_state.json" ]; then
            echo "âœ… Found state file in repository (fallback)"
            echo "ðŸ“„ Repo state file size: $(wc -c < upload_state.json) bytes"
            STATE_FOUND=true
          fi
          
          if [ "$STATE_FOUND" = "false" ]; then
            echo "â„¹ï¸ No previous state found - will create new state on first run"
          fi
      
      - name: Check state file
        run: |
          if [ -f "repo/upload_state.json" ]; then
            echo "âœ… State file found"
            echo "State file size: $(wc -c < repo/upload_state.json) bytes"
            echo "Completed files: $(jq '.completed | length' repo/upload_state.json 2>/dev/null || echo 0)"
          else
            echo "âš ï¸ State file NOT found - will create new state"
          fi
        working-directory: .
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install rclone
        run: |
          curl https://rclone.org/install.sh | sudo bash
          rclone version
      
      - name: Setup GitHub CLI (for state uploads)
        run: |
          type -p curl >/dev/null || (sudo apt-get update && sudo apt-get install curl -y)
          curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg \
          && sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg \
          && echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null \
          && sudo apt-get update \
          && sudo apt-get install gh -y
        continue-on-error: true
      
      - name: Configure rclone
        run: |
          mkdir -p ~/.config/rclone
          echo "${{ secrets.RCLONE_CONFIG }}" > ~/.config/rclone/rclone.conf
          chmod 600 ~/.config/rclone/rclone.conf
          echo "Rclone config created"
      
      - name: Test rclone connection
        run: |
          rclone lsd Challenger: || echo "Warning: Could not list directories"
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg p7zip-full
      
      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install https://github.com/xob0t/google_photos_mobile_client/archive/refs/heads/main.zip --force-reinstall
          pip install requests
      
      - name: Run transfer script (with periodic state upload)
        env:
          GP_AUTH_DATA: ${{ secrets.GP_AUTH_DATA }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        working-directory: repo
        run: |
          # Run script in background and periodically upload state
          python3 ftp_to_gphotos.py &
          SCRIPT_PID=$!
          
          # Upload state every 30 minutes while script runs
          while kill -0 $SCRIPT_PID 2>/dev/null; do
            sleep 1800  # 30 minutes
            if [ -f "upload_state.json" ]; then
              echo "ðŸ“¤ Uploading state file (periodic backup)..."
              gh run upload ${{ github.run_id }} upload_state.json --name upload-state --pattern upload_state.json || true
            fi
          done
          
          # Wait for script to finish
          wait $SCRIPT_PID
          SCRIPT_EXIT=$?
          
          # Final state upload
          if [ -f "upload_state.json" ]; then
            echo "ðŸ“¤ Final state file upload..."
            gh run upload ${{ github.run_id }} upload_state.json --name upload-state --pattern upload_state.json || true
          fi
          
          exit $SCRIPT_EXIT
        continue-on-error: true
      
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: transfer-logs
          path: |
            repo/ftp_to_gphotos.log
          retention-days: 7
      
      - name: Upload state for next run (final)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: upload-state
          path: repo/upload_state.json
          retention-days: 90
          overwrite: true
      
      - name: Check disk space
        if: always()
        run: |
          df -h
          du -sh ~/* 2>/dev/null || true

